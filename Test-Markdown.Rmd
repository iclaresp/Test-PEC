---
title: "Clares-Pedrero-Irene"
author: "I. Clares"
date: "2024-10-31"
output: 
 html_document:
    code_folding: show
    toc: true
    toc_float: true
    theme: spacelab
    highlight: tango
self_contained: true
---

```{r setup, include=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(tidy.opts = list(width.cutoff = 60), tidy = TRUE)
library(Biobase)
library(BiocManager)
library(SummarizedExperiment)
library(knitr)
library(devtools)
library(readxl)
library(readr)
library(tibble)
library(dplyr)
library(formatR)
library(RCurl)
library(R.utils)
```

# Presentación y objetivos

Esta PEC trata de planificar y ejecutar una versión simplificada del proceso de análisis de datos ómicos, empleando diversas herramientas y métodos.

## Resumen de objetivos

El trabajo que se pretende desarrollar se resume en:

1.  Seleccionar un dataset de metabolómica desde un repositorio de [github](https://github.com/nutrimetabolomics/metaboData/) o desde el repositorio de [Metabolomics Workbench](https://www.metabolomicsworkbench.org/).

2.  Crear un contenedor del tipo `SummarizedExperiment` que contenga los datos y los metadatos (información acerca del *dataset*, las filas y las columnas).

    La clase `SummarizedExperiment` es una extensión de `ExpressionSet` y muchas aplicaciones o bases de datos (como metabolomicsWorkbench) lo utilizan en vez de usar `ExpressionSet`.

3.  Llevar a cabo una exploración del `dataset` para proporcionar una visión general del mismo.

4.  Elaborar un informe que describa el proceso que realizado, incluyendo la descarga de los datos, la creación del contenedor, la exploración de los datos y la reposición de los datos en github. Este repositorio se llamará: "Clares-Pedrero-Irene-PEC1".

5.  Crear un repositorio de `github` que contenga:

-   El informe
-   El objeto contenedor con los datos y los metadatos en formato binario (.Rda)
-   El código R para la exploración de los datos
-   Los datos en formato texto
-   Los metadatos acerca del *dataset* en un archivo markdown. La dirección (url) del repositorio deberá estar incluida en la última sección del informe de forma clara.

# Introducción

A modo de introducción, hablaremos sobre la clase `SummarizedExperiment`. Esta clase almacena matrices de resultados experimentales, comúnmente obtenidos a partir de secuenciaciones o *microarrays*. Cada objeto de esta clase, almacena informacion de una o más muestras, así como mmetadatos adicionales que descriven tanto observaciones (*features*) como muestras (*phenotypes*).

Es un formato similar al clásico `ExpressionSet`, la principal diferencia radica en que es más flexible en cuanto a información por filas. Esto le hace más adecuado para algunos experimentos como RNA-Seq y ChIp-Seq.

Para trabajar con `SummarizedExperiment` contamos con un paquete propio con el mismo nombre. Este paquete contiene dos clases: `SummarizedExperiment` y `RangedSummarizedExperiment`.

`SummarizedExperiment` es un contenedor tipo matriz en el que las filas representan características de interés (genes, transcritos, exons, etc.) y las columnas representan las muestras o entradas de datos.

Las características representadas en las filas de `SummarizedExperiment` están detalladas en un objeto de tipo `Dataframe` , accesible usando la función `rowData()`. Cada fila del dataframe ofrece informacion de la característica de interés para la fila correspondiente en el `SummarizedExperiment`. Las columnas del `DataFrame` representan differentes atributos de la característica, como ID de genes or transcritos.

# 1. Selección del *dataset* de estudio.

Tras revisar los datos disponibles en el repositorio de github, nos decidimos a emplear los datos contenidos en la carpeta [2024-fobitools-UseCase_1](https://github.com/nutrimetabolomics/metaboData/blob/main/Datasets/2024-fobitools-UseCase_1). Estos datos han sido descargados desde el repositorio de metabolomics Workbench bajo la ID [ST000291](https://www.metabolomicsworkbench.org/data/DRCCMetadata.php?Mode=Study&StudyID=ST000291).

Los datos mostrados corresponden a un experimento diseñado para estudiar cambios metabólcos causados por la concentración en procianidinas presentes en el zumo de grosellas o de manzanas. Se tomaron muestras de sangre y/o orina.

Estos datos constan de 3 archivos diferentes:

1.  `features.csv`. Corresponde a los datos analizados, cada columna corresponde a una muestra biológica (un individuo de estudio o lo que se denomina `sample`) y cada fila corresponde a una lectura de la característica de interés.
2.  `metadata.csv`. Contienen 45 filas que corresponden con las 45 columnas del archivo `features.csv` y dos columnas que describen el nombre de la muestra y el nombre de su grupo.
3.  `metaboliteNames.csv`. Describe el nombre de los metabolitos, tanto su nombre original como su ID en PubChem y en KEGG.

# 2. Construcción de `SummarizedExperiment`.

Podemos construir nuestro objeto `SummarizedExperiment` (SE) descargando los 3 archivos por separado y construyendo el SE *de novo*.

## Importando archivos

Por defecto, un `SummarizedExperiment` puede construirse únicamente con una matriz de datos; aunque trabajar con un `SummarizedExperiment` que no cuente con metadatos de las muestras ni medidas sólo puede hacer análisis básicos por lo que ahora no nos será suficiente.

Comenzamos cargando en el entorno el archivo `features.csv` que es el que contiene las observaciones realizadas para cada una de las muestras. NOTA: Si hicimos una exploración previa de los datos en GitHub, habremos visto que el carácter seprador de los datos en estos archivos es ';', lo que deberemos indicar a la hora de leerlos.

Cargamos los archivos:

```{r}

# Importamos el archivo features, que nos servirá de assay

features <- read.csv("features.csv", sep = ';', row.names = 1)
features[1:5, 1:5] # Visualizamos las primeras entradas de datos
dim(features) # Comprobamos que las dimensiones correspondan con las esperadas

```

Con esto, tenemos suficiente para crear un `SummarizedExperiment` rudimentario usando en constructor de Bioconductor. Usamos la matriz de datos `features` bajo el nombre "counts":

```{r}

# Creamos el SummarizedExperiment con el constructor

SE_features <- SummarizedExperiment(assays = list(counts = features))
SE_features # Visualizamos el SE

```

Hemos construido un SE que contiene un assay con 1541 entradas de datos para 45 muestras. El nombre de las filas es un código numérico (sólo se muestran las dos primeras y las dos segundas) y las muestras corresponden a un código alfanumérico de una única letra seguida de un número. Por el momento no tenemos ninguna información de fila o de columna.

Si queremos crear un SE más detallado, podemos importar metadatos correspondientes a las muestras y a los metabolitos.

Dado que los archivos tienen un formato similar al archivo que contenía los datos de recuento (`features`), recurrimos a las mismas instrucciones.

```{r}

sample_metadata <- read.csv("metadata.csv", sep = ';', row.names = 1)
head(sample_metadata,5)

metabolite_metadata <- read.csv("metaboliteNames.csv", sep = ';', row.names = 1)
head(metabolite_metadata,5)

```

Ya tenemos importados los conjuntos de datos que emplearemos para construir nuestro `SummarizedExperiment` por lo que pasamos a la siguiente fase.

## Creación del `SummarizedExperiment`.

Teniendo ya cargados los archivos, podríamos intentar crear ya por fin nuestro `SummarizedExperiment` empleando el mismo comando constructor y actualizando la información que queremos usar.

### Primer intento

El código mostrado a continuación corresponde a la instrucción que debería usarse para construir el `SummarizedExperiment` a partir de nuestros objetos, sin embargo al correr el código, el terminal lleva a error.

```{r, eval=F, echo=T}

SE_added <- SummarizedExperiment(assays = list(counts = features),
                                 colData = sample_metadata,
                                 rowData = metabolite_metadata) # Metadatos de 
                                                                # metabolitos

SE_added


```

*NOTA: en las opciones del bloque de código se ha escrito:* `{r, eval=F, echo=T}` *para que se muestre el código pero no corra ni se evalúe durante la exportación.*

El terminal resultante de ejecutar este código nos devuelve el mensaje:

`Error in SummarizedExperiment(assays = list(counts = features), colData = sample_metadata,  : the rownames and colnames of the supplied assay(s) must be NULL or identical to those of the SummarizedExperiment object (or derivative) to construct`

Vemos que algo está pasando en el proceso de cruce de referencias entre la matriz de los datos y los metadatos de muestras y/o metabolitos.

### Observación de los datos

Dado que el error que se nos devuelve indica una falta de correspondencia entre nombres de las columnas y/o filas de `features` con las de los archivos `sample_metadata`y `metabolite_metadata`, procedemos a una comprobación lógica sencilla.

```{r}

# Comprobamos si hay correspondencia entre los nombres de columnas de features
# y el nombre de filas de sample_metadata

summary(colnames(features)==rownames(sample_metadata)) #Obtenemos la tabla resumen

# Comprobamos si hay correspondencia entre los nombres de filas de features
# y el nombre de filas de metabolite_metadata
summary(rownames(features)==rownames(metabolite_metadata))

```

Dada la naturaleza de los `SummarizedExperiment`, el nombre de las columnas contenidas en el archivo con los datos de las muestras (el `assay`, que es `features` en nuestro caso), debería corresponderse con los nombres de las filas de los metadatos de las mismas. Esto se debe a que los metadatos de las muestras dan información sobre las covariables que afectan a las mismas.

Como vemos, esto no ocurre entre nuestros conjuntos de datos por lo que es necesario que nos paremos a observarlos detenidamente.

El primer paso, y quizá lo que debía haberse hecho desde el principio; es observar el nombre de las filas (`row.names`) de los dataset correspondientes a los metadatos:

```{r}

# Usamos la instrucción row.names() y visualizamos las primeras salidas de datos

head(row.names(sample_metadata),5)
head(row.names(metabolite_metadata),5)

```

Como vemos, el nombre de fila (`row name`) de ambos *dataset* es un vector numérico cardinal. Esto es lo que nos estaba llevando a error al emplear el constructor.

Nuestro siguiente paso será arreglar las correspondencias entre *datasets* para hacer coincidir los nombres correspondientes.

### Modificación de `row names`.

#### Modificación de `sample_dataset`.

En primer lugar vamos a tratar al objeto `sample_metadata` para hacer que los nombres de las filas coincidan con los de las columnas de `features`.

Podemos hacerlo de varias formas:

-   Modificar la instrucción de lectura del archivo de modo que al ejecutar `read.csv()` sobre `sample_metadata` se tomen como valores de `rownames` la información contenida en la primera columna(la que corresponde a la **ID**).
-   Sobreescribir los datos ya importados con la información contenida en la primera columna del objeto.
-   Extraer los valores contenidos en la columna ID del dataframe que contiene los metadatos de las muestras en un vector y sustituir los `rownames()` por los valores del vector.

Pasamos a demostrar las 3 formas.

```{r}

# METODO 1.
# Indicamos que los valores de row.names están en la segunda columna cuando
# importamos el archivo.

sample_metadata_c2 <- read.csv("metadata.csv", sep = ';', row.names = 2)
head(sample_metadata_c2,5) # Obtenemos un dataframe con las columnas desordenadas

# MÉTODO 2.
# En un nuevo dataframe, indicamos que queremos como rownames los valores
# contenidos en la primera columna, que corresponde a las IDs de las muestras.

sample_metadata_mod <- sample_metadata
rownames(sample_metadata_mod) <- sample_metadata[,1] # Redefinimos rownames con 
                                                     # valores de la columna 1
head(sample_metadata_mod,5) # Obtenemos un dataframe en el que el nombre de las filas
                    # es el que deseamos, aunque parece que hayamos duplicado
                    # los datos.

# MÉTODO 3.
# Creamos un vector con los datos de la columna ID y los establecemos como 
# nuevos valores de row.names()

sample_rownames <- sample_metadata$ID # Creamos el vector de datos
sample_md_row <- sample_metadata # Nuevo dataset a partir de sample_metadata
row.names(sample_md_row) <- sample_rownames # Hacemos la sustitución
head(sample_md_row,5) # El nuevo dataframe tiene los nombres de fila cambiados

```

Es posible comprobar si estos métodos nos ofrecen el resultado esperado haciendo una comparación lógica similar a la empleada anteriormente:

```{r}

summary(colnames(features)==rownames(sample_metadata_c2))
summary(colnames(features)==rownames(sample_metadata_mod))
summary(colnames(features)==rownames(sample_md_row))

```

Vemos que cualquiera de los tres métodos es válido para provocar que el nombre de las filas del *dataset* que contiene los metadatos de las muestras coincida con el nombre de las columnas de los datos de las muestras.

Podemos hacer una comparativa entre estas 3 modificaciones para ver que los resultados son muy similares; salvo en el caso de forzar el reconocimiento de `row.names`. En este caso vemos que al modificar las opciones de la instrucción `read.csv()` el orden de las columnas se ha "modificado" y la lista de números que antes era el `row names` ahora parece consolidarse como una nueva covariable llamada "row.names".

```{r}

summary(sample_metadata_c2 == sample_metadata_mod)
summary(sample_metadata_mod == sample_md_row)

```

Como vemos, `sample_metadata_mod` y `sample_md_row` son idénticas entre sí, por lo que nos es indiferente cuál usar. La comparativa entre `sample_metadata_md` y `sample_metadata_mod` nos da error al comparar la primera columna y esto se debe a que, como comentábamos, se ha hecho una reordenación en las columnas. Como no sabemos si esto nos llevará a error a posteriori, decidimos descartar el uso de `sample_metadata_md` en favor de las otras dos alternativas.

Por el momento usaremos `sample_md_row` ya que utiliza el mismo *pipeline* de construcción que usaremos para modificar los metadatos de los metabolitos.

COn esto, ya podríamos volver a intentar construir el `SummarizedExperiment` ya que contamos con el argumento `ColData()`, que no es más que los metadatos de la muestra y que ya corresponden con los datos de `features`. Sin embargo aún nos queda un *dataset* por incorporar al SE.

#### Modificación de `metabolites_dataset`

De forma similar a lo que hicimos en el subapartado anterior, vamos a hacer que los nombres de las filas en `metabolites_dataset` coincidan con los de las filas de `features`.

Para ello seguiremos lo que antes tomábamos como tercer posible método: extraer los valores contenidos en una columna dataframe y usarlos como nuevos `rownames()`.

Redefinimos los `rownames` para que coincidan con los valores de rowname de `features`. Un vistazo a ambos conjuntos de datos evidenciarán que la ID de los metabolitos de `features` corresponde a los que aparecen en la columna `PubChem` de `metabolite_metadata`.

```{r}

#Visualizamos las primeras entradas del dataset
head(metabolite_metadata)

met_rownames <- metabolite_metadata$PubChem # Creamos un vector con los valores de la
                                      # columna que luego usaremos como row.name 
metabolite_md_row <- metabolite_metadata # Nuevo dataset a partir de sample_metadata
row.names(metabolite_md_row) <- met_rownames # Hacemos la sustitución
head(metabolite_md_row,5) # El nuevo dataframe tiene los nombres de fila cambiados

```

Ya hemos redefinido los nombres de las filas del dataset que contiene los metadatos de los metabolitos; pero si hacemos una comprobación rápida veremos que los row.names() de `features` y el nuevo `metabolite_md_row` no coinciden todavía.

```{r}

summary(row.names(features)==row.names(metabolite_md_row))

```

Esto es porque el nombre que hace referencia a los metabolitos en `metabolite_md_row` no está en el mismo orden en el que se recoge en los datos de las muestras en `features`, lo cual nos supone un nuevo problema.

Aunque es poco elegante, en aras de que haya la mayor coincidencia posible entre los datos, podemos reordenar numéricamente los datos de las muestras y los metadatos de los metabolitos.

Usando en ambos casos el valor del nombre de fila, podemos reordenar las filas de modo que los `row.names()` queden ordenados de menor a mayor. De esta forma estamos forzando la coincidencia entre `rownames` de ambos archivos.

ATENCIÓN: es importante recordar que debemos trabajar con el dataset en el que los nombres de las filas ya han sido modificados, sino, la reordenación no se haría porque los `rownames` son un listado numérico ya ordenado.

```{r}

# Creamos un nuevo objeto en el que hayamos reordenado los valores en base al
# nombre de las filas de features.
features_sorted <- features[order(as.numeric(row.names(features))),]
head(features_sorted,5) # Visualizamos

# Repetimos el proceso con metabolite_md_row
metab_md_sorted <- metabolite_md_row[order(as.numeric(
  row.names(metabolite_md_row))),]
head(metab_md_sorted,5)

```

Ya hemos reordenado los datos de ambos conjuntos. Al visualizarlos, vemos que en `features_sorted` hay datos NA. Volveremos a ello más adelante.

Comprobamos ya si hay correspondencia entre los nombres de filas de los datos con las muestras y los metadatos de los metabolitos.

```{r}

summary(row.names(features_sorted) == row.names(metab_md_sorted))

```

El terminal nos indica que los nombres de las filas ya sí son idénticos entre sí.

Con todo esto y una vez modificados los datos como compete, podemos volver a intentar construir el `SummarizedExpression`.

### Construcción del `SummarizedExperiment`.

Ya contamos con nuestros datos procesados, por lo que intentamos de nuevo construir nuestro `SummarizedExpression`.

Usaremos las siguientes opciones en el constructor:

-   `features_sorted` como `assay` para recoger las medidas del experimento.
-   `sample_md_row` como `colData` para dar información de las muestras.
-   `metab_md_sorted` como `rowData` para dar información sobre los metabolitos.

Creamos nuestro `SummarizedExperiment`:

```{r}

SE_PEC <- SummarizedExperiment(assays = list(counts = features_sorted),
                                 colData = sample_md_row,
                                 rowData = metab_md_sorted)
SE_PEC

```

Para nuestro gran regocijo, ya hemos conseguido construir un `SummarizedExperiment` a partir de nuestros archivos .csv descargados en el repositorio.

![](https://media1.tenor.com/m/cMfykA6dgwEAAAAd/there-was-much-rejoicing-monty-python.gif)

## Usando `metabolomicsWorkbenchR`

Dado que uno de los objetivos de la PEC era ser capaces de construir un `SummarizedExperiment` a partir de los datos descargados, es lo que hemos hecho en los subapartados anteriores con mayor o menor éxito.

La otra cara de la moneda es que, por fortuna, todos los experimentos recogidos en el repositorio de metabolomics Workbench son accesibles desde el paquete `metabolomicsWorkbenchR` de `Bioconductor`.

Si instalamos y cargamos el paquete `metabolomicsWorkbenchR`, podemos importar diferentes `SummarizedExperiment` e interrogar sobre los mismos haciendo instrucciones del tipo `do_query()`.

```{r, eval=F, echo=T}

# Instucciones de instalación de paquetes en caso de ser necesario, lo hacemos
#código no ejecutable para este bloque

if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")

BiocManager::install(c("SummarizedExperiment","metabolomicsWorkbenchR"))

```

Si ya tenemos cargados los paquetes necesarios, vemos que con una simple instrucción podemos acceder al `SummarizedExperiment` que se corresponde al estudio ST000291 de Metabolomics Workbench a través de R. Es una instrucción más simple; pero que tarda consustancialmente más en ejecutarse.

```{r}

library("metabolomicsWorkbenchR")
SE_metWB = do_query(
    context = 'study',
    input_item = 'study_id',
    input_value = 'ST000291',
    output_item = 'SummarizedExperiment' # or 'DatasetExperiment'
)

SE_metWB

head(assay(SE_metWB),3)

```

Como resultado, obtendremos también un `SummarizedExperiment` de características medianamente similares al nuestro; aunque basta con una simple visualización de éste para darnos cuenta que es mucho más completo. Esto se debe, seguramente, a que este `SummarizedExperiment` cuenta con más información de la que tenemos nosotros en nuestos dos archivos, lo que se ve a simple vista al observar la salida `colData names`, que es de 2 en nuestro caso y de 6 en el de `metabolomicsWorkbenchR`.

En cualquier caso, ya tenemos nuestro contenedor y pasaremos a trabajar con él.

# 3. Análisis exploratorio de los datos

Una vez contamos con nuestro contenedor `SummarizedExperiment` ya creado, procedemos a hacer un análisis exploratorio de los datos similar al que hemos visto en algunos casos de estudio.

## Estructura y valores `NAs`.

El análisis más sencillo es el de la estructura de los datos de los que disponemos y la observación de los datos.

Ya conocemos las dimensiones de los dataset que componen el contenedor; pero no está de más recordarlo. A modo de exploración anectdótica vemos las dimensiones de cada componente y datos sobre alguna covariable:

```{r}

dim(SE_PEC) # Dimensiones del SummarizedExperiment
dim(assay(SE_PEC)) # Dimensiones de la matriz de datos
dim(rowData(SE_PEC))
dim(colData(SE_PEC))
unique(SE_PEC$Treatment) # Tratamientos únicos.

print(paste("Tendremos", sum(SE_PEC$Treatment == "Baseline"), 
            "muestras que no han sido tratadas,", 
            sum(SE_PEC$Treatment == "Apple"),
            "con tratamiento de zumo de manzana y", 
            sum(SE_PEC$Treatment == "Cranberry"), 
            "con zumo de grosellas"))


```

Tenemos un objeto con 1541 entradas datos correspondientes a 45 muestras diferentes de las que se han tomado lecturas para 1541 metabolitos. Las muestras se subagrupan en 3 grupos según el tratamiento que hayan recibido.


Además, si recordamos lo visto anteriormente en el subapartado en el que ordenamos los metadatos y las muestras, observamos que algunas filas contenían valores NA. Podemos comprobar esto con una simple instrucción.

```{r}

table(summary(is.na(assay(SE_PEC))))

```

Como vemos, hay 182 instancias en las que se reconoce que hay valores NA en los datos. Aunque por el momento no estamos demasiado versados en el uso de `SummarizedExperiments`, sabemos por experiencias anteriores que la presencia de NAs en los datos tiende a emborronar o impedir en cierta forma cualquier intento de análisis de los datos.

Dado que no sabemos si esto va a cumplirse en el caso de contenedores `SummarizedExperiments`, decidimos suprimirlos del nuestro para evitar sorpresas. Tomamos esta decisión porque podemos suponer que todo dato no registrado se debe a que la lectura del metabolito fue errónea por algún fallo de metodología o que directamente no era un metabolito de interés, por lo que su omisión no debería afectar a nuestro análisis.

Para eliminar las filas que contengan NAs, podemos hacer una búsqueda dentro del `SummarizedExperiment`. Crearemos un vector con el índice de las filas que **no** contengan NAs y haremos un *subsetting* de nuestro NE para obtener los datos "completos".

Crearemos nuestro vector seleccionando el inverso (`!`) del análisis que detecta dónde se localizan lecturas NA (`is.na`).

```{r}

#Extraemos un vector que contenga índices de filas completas
vector_full <- which(!(is.na(assay(SE_PEC)[[1]])))
length(vector_full) # Visualizamos la cantidad de filas

# Hacemos el subsetting de nuestro SE
SE_PEC_full <- SE_PEC[c(vector_full),]
SE_PEC_full # Visualizamos el resumen del SE

# Podemos visualizar la matriz de datos para ver si nos hemos librado de los NA

assay(SE_PEC_full)[1:10, 1:5]

```

Ya tenemos un `SummarizedExperiment` sin valores NA que puedan alterar de cualquier forma nuestros análisis. Podemos pasar a estudios más complejos.


## Análisis univariante de los datos

Es la forma más sencilla de análisis de nuestros datos, ya que estudia las variables de forma independiente. Examina las variables para explorar propuedades estadísticas y estructurales como son dispersión de datos, valores atípicos (*outliers*) y su tendencia central.

Vamos a hacernos una idea de los valores estadísticos de las muestras gracias a 
De un vistazo rápido, podemos hacernos una idea  de las estadísticas de cada muestra usando la función `summary()`.

```{r}

head(summary(assay(SE_PEC_full)[,1:5]))

```

Simplemente con el resumen estadístico de las muestras vemos que se evidencia una clara asimetría en ellos: los mínimos están en 0 y los máximos adquieren valores del orden e+10.

Para facilitar la comprensión del análisis univariante podemos emplear gráficos como **boxplots** o **histogramas**. 

Dada la naturaleza de nuestros datos (n=45), decidimos usar los boxplots como herramienta de representación gráfica del análisis univariante.
Querer generar 45 histogramas diferentes es no sólo ambicioso sino muy demandante y los límites de la representación se resienten.

```{r}
# Creamos un vector con los colores que usaremos luego en el boxplot
color <- c(rep("cyan3",15), rep("green3",15), rep("firebrick3",15))

boxplot(assay(SE_PEC_full), las=2, col = color, 
        main = "Boxplot de valores de expresión", xlab = "Samples")

```

El boxplot de los datos evidencia una clara asimetría en los mismos. Esto sugiere que quizá sea necesario hacer algún tratamiento a los mismos para tratar con ellos.

Un posible tratamiento de los datos puede ser una transformación logarítmica:

```{r}

boxplot(log(assay(SE_PEC_full)), las=2, col = color, 
        main = "Boxplot de valores de expresión", xlab = "Samples")

```

Vemos que la transformación logarítmica de los datos es necesaria y se nos muestra que los datos son bastante comparables entre sí. La presencia de outliers es clara y no se resuelve ni tan siquiera con la transformación logarítmica pero por el momento no es importante.

Podríamos recurrir al resumen estadístico de las muestras con `summary()`.

```{r}

SE_log <- log(assay(SE_PEC_full))
head(summary(SE_log[,1:5]))

```

Estos valores estadísticos tras el tratamiento de los datos es más "razonable" si tenemos en cuenta que no están tan dispersos. Esto probablemente se traduzca en un análisis posterior más robusto-


Al visualizar la estructura de los datos y sus estadísticas, se pone en evidencia que nuestros datos no se encontraban pre-procesados y que este proceso puede llegar a resultar fundamental para llevar a cabo un buen análisis posterior de los datos.

El principal inconveniente de estos análisis es que sólo nos están dando información a nivel de la muestra, es decir, resulta casi un informe cualitativo de los datos.

Si queremos intentar sacar conclusiones de nuestros datos, requerimos de un análisis más exhaustivo.

Vamos a meter un cambio nimio.